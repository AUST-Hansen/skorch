{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import enwik8_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = enwik8_data.hutter_raw_data(data_path='./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA, VALID_DATA, TEST_DATA, unique_syms = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = len(unique_syms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(g):\n",
    "    for x, y in g:\n",
    "        yield torch.from_numpy(x).long(), torch.from_numpy(y).long()\n",
    "\n",
    "class Enwik8Loader:\n",
    "    def __init__(self, _dataset, batch_size=128, num_steps=32, max_samples=None, **kwargs):\n",
    "        self.max_samples = max_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "    def __iter__(self):\n",
    "        return collate(enwik8_data.data_iterator(\n",
    "            self.dataset[slice(0, self.max_samples)], \n",
    "            self.batch_size, \n",
    "            self.num_steps))\n",
    "\n",
    "class Enwik8TrainLoader(Enwik8Loader):\n",
    "    dataset = TRAIN_DATA\n",
    "    \n",
    "class Enwik8ValidLoader:\n",
    "    dataset = VALID_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "class BatchPrinter(skorch.callbacks.Callback):\n",
    "    def __init__(self, update_interval=5):\n",
    "        self.update_interval = update_interval\n",
    "    def initialize(self):\n",
    "        self.batches_per_epoch = None\n",
    "        self.batch_counter = 0\n",
    "    def on_batch_begin(self, *args, **kwargs):\n",
    "        self.batch_start_time = time.time()\n",
    "    def on_batch_end(self, net, *args, train=True, **kwargs):\n",
    "        self.batch_end_time = time.time()\n",
    "        self.batch_counter += 1\n",
    "        if self.batch_counter % self.update_interval != 0:\n",
    "            return\n",
    "        \n",
    "        k = 'train_loss' if train else 'valid_loss'\n",
    "        loss = '{}: {:.3}'.format(k, net.history[-1, 'batches', -1, k])\n",
    "        \n",
    "        sys.stdout.write(\"Batch {}/{} complete ({:.2}s), {}.\\r\".format(\n",
    "            self.batch_counter, \n",
    "            self.batches_per_epoch,\n",
    "            self.batch_end_time - self.batch_start_time,\n",
    "            loss,\n",
    "        ))\n",
    "        sys.stdout.flush()\n",
    "    def on_epoch_end(self, *args, **kwargs):\n",
    "        if self.batches_per_epoch is None:\n",
    "            self.batches_per_epoch = self.batch_counter\n",
    "        self.batch_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_flatten(t):\n",
    "    return t.view(t.size(0) * t.size(1), -1)\n",
    "\n",
    "def time_unflatten(t, s):\n",
    "    return t.view(s[0], s[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReconModel(nn.Module):\n",
    "    def __init__(self, num_hidden=64, num_layers=1, visdom=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.visdom = visdom\n",
    "        self.emb = nn.Embedding(EMBEDDING_SIZE, num_hidden)\n",
    "        self.rnn = nn.GRU(num_hidden, num_hidden, num_layers=num_layers)\n",
    "        self.clf = nn.Linear(num_hidden, EMBEDDING_SIZE)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.emb(x.long())\n",
    "        l0, h0 = self.rnn(x_emb)\n",
    "        \n",
    "        if self.visdom:\n",
    "            self.visdom.heatmap(h0[0].data.numpy(), win=\"hidden\")\n",
    "            \n",
    "        l1 = self.clf(time_flatten(l0))\n",
    "        l1_sm = self.softmax(l1)\n",
    "        \n",
    "        return time_unflatten(l1_sm, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(skorch.NeuralNet):\n",
    "    def __init__(self, \n",
    "                 criterion=nn.NLLLoss,\n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__(*args, criterion=criterion, **kwargs)\n",
    "\n",
    "    def get_loss(self, y_pred, y_true, X=None, train=False):\n",
    "        pred = time_flatten(y_pred)\n",
    "        true = time_flatten(y_true).squeeze(-1)\n",
    "        return super().get_loss(pred, true, X=X, train=train)\n",
    "    \n",
    "    def score(self, *args, **kwargs):\n",
    "        try:\n",
    "            return self.history[-1, 'train_loss']\n",
    "        except KeyError:\n",
    "            return -42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "def my_train_split(X, y):\n",
    "    return X, X, y, y\n",
    "\n",
    "ef = Trainer(module=ReconModel,\n",
    "             optimizer=torch.optim.RMSprop,\n",
    "             lr=0.002,\n",
    "             max_epochs=2,\n",
    "                              \n",
    "             train_split=my_train_split,\n",
    "             iterator_train=Enwik8TrainLoader,\n",
    "             iterator_train__batch_size=128,\n",
    "             #iterator_train__max_samples=128*300,\n",
    "             iterator_train__num_steps=32,\n",
    "             \n",
    "             iterator_valid=Enwik8ValidLoader,\n",
    "             iterator_valid__batch_size=128,\n",
    "             iterator_valid__num_steps=32,\n",
    "             #iterator_valid__max_samples=None,\n",
    "\n",
    "             use_cuda=True,\n",
    "             \n",
    "             module__visdom=None,\n",
    "             module__num_hidden=256,\n",
    "             module__num_layers=4,\n",
    "             \n",
    "             callbacks=[BatchPrinter()]\n",
    "            )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%pdb on\n",
    "ef.fit(torch.zeros((10,1)), torch.zeros((10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/None complete (0.084s), train_loss: 2.91.\r"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr': [0.002, 0.02],\n",
    "    'module__num_hidden': [256, 320],\n",
    "}\n",
    "m = GridSearchCV(ef, params)\n",
    "m.fit(np.zeros((10,1)), np.zeros((10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
